# -*- coding: utf-8 -*-
"""Python_Machine_Learning_EAA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15XDOxFm6m1_mdd-Rmt4tFH2ucLtyKNtL
"""

# Errol Ian Ave Acosta
# Python (Personal)
# CGPT Project: Iris Flower Classification
# 9 November 2024

# Install Required Libraries:
!pip install scikit-learn pandas matplotlib

# Import Libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
import matplotlib.pyplot as plt
from sklearn.datasets import load_iris

# Step 2: Load the Dataset
# We’ll use the Iris dataset from sklearn.datasets. It’s already labeled, so we have both features and target values for training a classifier.
from sklearn.datasets import load_iris
import pandas as pd

# Load the dataset
iris = load_iris()
X = iris.data  # Features: sepal length, sepal width, petal length, petal width
y = iris.target  # Target: species

# Convert to DataFrame for easier visualization
df = pd.DataFrame(X, columns=iris.feature_names)
df['species'] = y
df.head()
X = iris.data  # Features: sepal length, sepal width, petal length, petal width
y = iris.target  # Target: species

# Convert to DataFrame for easier visualization
df = pd.DataFrame(X, columns=iris.feature_names)
df['species'] = y
df.head()

# Split data into training and testing sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 4: Train a Model
# For this task, use the Random Forest Classifier as it’s easy to implement and performs well on classification tasks.
# Initialize the model
model = RandomForestClassifier(n_estimators=100, random_state=42)
# Train the model
model.fit(X_train, y_train)

# Step 5: Make Predictions
# Now, use the trained model to make predictions on the test data.
# Predict on test data
y_pred = model.predict(X_test)

# Step 6: Evaluate the Model
# Measure the accuracy and check the classification report to see precision, recall, and F1-score.
# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy * 100:.2f}%")
# Print classification report
print(classification_report(y_test, y_pred, target_names=iris.target_names))
print(f"Accuracy: {accuracy * 100:.2f}%")
# Print classification report
print(classification_report(y_test, y_pred, target_names=iris.target_names))
print(f"Accuracy: {accuracy * 100:.2f}%")
# Print classification report
print(classification_report(y_test, y_pred, target_names=iris.target_names))
print(f"Accuracy: {accuracy * 100:.2f}%")
# Print classification report
print(classification_report(y_test, y_pred, target_names=iris.target_names))

# Step 7: Visualize the Results (Optional)
# Let's visualize the feature importance to understand which features the model considers most significant.
# Feature importance plot
importances = model.feature_importances_
feature_names = iris.feature_names
plt.figure(figsize=(8, 6))
plt.barh(feature_names, importances)
plt.xlabel("Feature Importance")
plt.title("Feature Importance in Iris Classification")
plt.show()

"""
Step 8: Summary and Next Steps

    Accuracy and Report: Review the accuracy and classification metrics to understand the model's performance.
    Feature Importance: This can help identify which features (e.g., petal width) are most useful for classification.

Next Steps

    Try Different Models: Test other classifiers like Support Vector Machines (SVM) or K-Nearest Neighbors (KNN).
    Fine-Tune Parameters: Use Grid Search or Random Search to improve model performance.
    Add Cross-Validation: Use cross-validation to make the evaluation more robust.

This project gives you a full cycle of a simple machine learning project from data loading to model evaluation. Let me know if you’d like more depth on any step!

"""